{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from config import PostProcessConfig as PPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  speech_recognition  start     end  max_confidence  mean_confidence\n",
       "0             speech   27.0   27.63        0.943104         0.941218\n",
       "1             speech  147.0  148.00        0.999996         0.999991\n",
       "2             speech  149.0  150.00        0.999713         0.995705\n",
       "3             speech  150.0  151.00        1.000000         1.000000\n",
       "4             speech  151.0  152.00        0.996384         0.992788"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>speech_recognition</th>\n      <th>start</th>\n      <th>end</th>\n      <th>max_confidence</th>\n      <th>mean_confidence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>speech</td>\n      <td>27.0</td>\n      <td>27.63</td>\n      <td>0.943104</td>\n      <td>0.941218</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>speech</td>\n      <td>147.0</td>\n      <td>148.00</td>\n      <td>0.999996</td>\n      <td>0.999991</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>speech</td>\n      <td>149.0</td>\n      <td>150.00</td>\n      <td>0.999713</td>\n      <td>0.995705</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>speech</td>\n      <td>150.0</td>\n      <td>151.00</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>speech</td>\n      <td>151.0</td>\n      <td>152.00</td>\n      <td>0.996384</td>\n      <td>0.992788</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv(\"./inference/test.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechNode(object):\n",
    "    def __init__(self, cat:str=\"speech\", onset:float=0, offset:float=0, mac:float=0, mec:float=0) -> None:\n",
    "        self.cat = cat\n",
    "        self.onset = onset\n",
    "        self.offset = offset\n",
    "        self.mac = mac\n",
    "        self.mec = mec\n",
    "\n",
    "        self.next = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechSeries(object):\n",
    "    def __init__(self, df: pd.DataFrame) -> None:\n",
    "        self.df = df\n",
    "        self.columns = df.columns\n",
    "        self._Node = SpeechNode\n",
    "        self._head_node = None\n",
    "        self._ori_len = len(df)\n",
    "        assert len(self.df.columns)==5, \"Numbers of features in your inference output csv file is not right. \\\n",
    "                                        There should be 5 columns for post process.\"\n",
    "        self._build_linked_list()\n",
    "\n",
    "    def _build_linked_list(self):\n",
    "        pre_node = None\n",
    "\n",
    "        for s in self.df.itertuples():\n",
    "            node = self._Node(\n",
    "                s.speech_recognition,\n",
    "                s.start,\n",
    "                s.end,\n",
    "                s.max_confidence,\n",
    "                s.mean_confidence\n",
    "            )\n",
    "\n",
    "            if self._head_node == None:\n",
    "                self._head_node = node\n",
    "                pre_node = self._head_node\n",
    "                continue\n",
    "            \n",
    "            pre_node.next = node\n",
    "\n",
    "            pre_node = node\n",
    "\n",
    "    # TODO: Examine this method.\n",
    "    def _merge_node(self, n1, n2):\n",
    "        assert n2.onset >= n1.offset, \"Node input order reversed.\"\n",
    "        n1.offset = n2.offset\n",
    "        n1.next = n2.next\n",
    "\n",
    "    # TODO: Used With hooks.\n",
    "    def _break_node(self, n, timestamp: float):\n",
    "        new_offset = timestamp - PPC.break_period/2\n",
    "        new_onset = timestamp + PPC.break_period/2\n",
    "\n",
    "        new_node = self._Node(\n",
    "            n.cat,\n",
    "            new_onset,\n",
    "            n.offset,\n",
    "            n.max_confidence,\n",
    "            n.mean_confidence\n",
    "        )\n",
    "\n",
    "        n.offset = new_offset\n",
    "\n",
    "        new_node.next = n.next\n",
    "        n.next = new_node\n",
    "\n",
    "    def _post_process(self):\n",
    "        \"\"\"\n",
    "        Better formatted source for encoder after passing through the algorithm.\n",
    "        \"\"\"\n",
    "        speech = self._head_node\n",
    "\n",
    "        while speech.next != None:\n",
    "            # Increase the offset properly.\n",
    "            cur_time_gap = speech.offset - speech.onset\n",
    "            bet_time_gap = speech.next.onset - speech.offset\n",
    "\n",
    "            # If the gap between speeches is loose, add proper delay at the end.\n",
    "            if bet_time_gap >= PPC.loose_dialogue_threshold:\n",
    "                speech.offset += PPC.loose_dialogue_delay\n",
    "            # If the gap between speeches is so tight, merge them together. \n",
    "            elif bet_time_gap < PPC.standard_dialogure_break/2:\n",
    "                self._merge_node(speech, speech.next)\n",
    "            # If the dialogue are not loose but also not tight enough to merge them together, make the break standard.\n",
    "            else:\n",
    "                bias = (PPC.standard_dialogure_break -bet_time_gap) / 2\n",
    "                speech.offset -= bias / 2\n",
    "                speech.next.onset += bias / 2\n",
    "\n",
    "            # TODO: Need hooks to implement in-clip break.\n",
    "            if cur_time_gap > PPC.max_sigle_speech_length:\n",
    "                pass\n",
    "\n",
    "            speech = speech.next\n",
    "\n",
    "        speech.offset += PPC.loose_dialogue_delay\n",
    "\n",
    "    @property\n",
    "    def series(self):\n",
    "        self._post_process()\n",
    "\n",
    "        speech = self._head_node\n",
    "        columns = self.df.columns\n",
    "        df = pd.DataFrame(index=None, columns=columns)\n",
    "        \n",
    "        while speech != None:\n",
    "            s = [\n",
    "                speech.cat,\n",
    "                speech.onset,\n",
    "                speech.offset,\n",
    "                speech.mac,\n",
    "                speech.mec\n",
    "                ]\n",
    "            d = dict(zip(self.df.columns, s))\n",
    "            \n",
    "            df = df.append(d, ignore_index=True)\n",
    "\n",
    "            speech = speech.next\n",
    "\n",
    "        return df"
   ]
  }
 ]
}