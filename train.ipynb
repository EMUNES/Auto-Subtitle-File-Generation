{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('asg': conda)",
   "metadata": {
    "interpreter": {
     "hash": "7c1e26b787ea84c0136f54dc33c70b3c054a8e0cf94179623b14c46360f5a1e6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Train your model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from catalyst.dl import SupervisedRunner, State, CallbackOrder, Callback, CheckpointCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train.util import DirConfig\n",
    "from csrc.configurations import DatasetConfig as DC\n",
    "from csrc.configurations import ModelConfig as MC\n",
    "from csrc.utils import seed_dataset, seed_all"
   ]
  },
  {
   "source": [
    "## Train configurations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For better debugging.\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training clip length (sencods): 3\n"
     ]
    }
   ],
   "source": [
    "### The folder name of your dataset.\n",
    "DATASET = \"standard-p3\"\n",
    "\n",
    "### Whether you have split your dataset.\n",
    "### If False then the test dataset will be generated as configured in TrainParams and choose the split ratio.\n",
    "BUILD_TEST = False\n",
    "PREBUILD_TEST = False\n",
    "TEST_RATIO = 5\n",
    "\n",
    "### The ratio to split your train/validaion dataset.\n",
    "VALID_RATIO = 5\n",
    "### Whether to shuffle the dataset.\n",
    "SHUFFLE = True\n",
    "\n",
    "### Clip length that will be used for training.\n",
    "### Default to be the same as the audio clip length in the dataset.\n",
    "PERIOD = DC.dataset_clip_time\n",
    "print(f\"Training clip length (sencods): {PERIOD}\")\n",
    "\n",
    "### Batch size for training. For example: 8gb GPU for 5s clips - batch size 32.\n",
    "BS = 48\n",
    "\n",
    "### Training epochs.\n",
    "EPOCHS = 50\n",
    "\n",
    "### Weights file path used for training.\n",
    "### Default under weights folder.\n",
    "WEIGHTS_PATH = \"./weights/Cnn14_DecisionLevelAtt_mAP0.425.pth\"\n",
    "\n",
    "### Default path to store your model.\n",
    "LOG_DIR = \"./train/logs/trial/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seeding.\n",
    "# Change seed will change your validation set randomly picked from the dataset.\n",
    "\n",
    "SEED = 42\n",
    "seed_all(SEED)\n",
    "seed_dataset(SEED)"
   ]
  },
  {
   "source": [
    "## Process"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "FOLDER_FOR_TRAINING: d:\\Dev\\asg\\data\\standard-p3\nFOLDER_FOR_TEST: d:\\Dev\\asg\\data\\standard-p3\n"
     ]
    }
   ],
   "source": [
    "# Set up working folder for training.\n",
    "\n",
    "dirs = DirConfig(DATASET, PREBUILD_TEST)\n",
    "DATASET_FOLDER = dirs.dataset_folder\n",
    "TRAIN_FOLDER = dirs.train_folder\n",
    "TEST_FOLDER = dirs.test_folder\n",
    "\n",
    "### Currently we are training so we set up the training folder as the working folder.\n",
    "TRAIN_WORKING_FOLDER = TRAIN_FOLDER\n",
    "TEST_WORKING_FOLDER = TEST_FOLDER if TEST_FOLDER else TRAIN_FOLDER\n",
    "\n",
    "print(f\"FOLDER_FOR_TRAINING: {TRAIN_WORKING_FOLDER}\")\n",
    "print(f\"FOLDER_FOR_TEST: {TEST_WORKING_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files for training: 15228\nFiles for testing: 3806\n"
     ]
    }
   ],
   "source": [
    "# Train/Test split. If the test folder has not been manually selected, then split the test folder.\n",
    "\n",
    "def sort_index(x):\n",
    "    return int(x.split(\"-\")[0])\n",
    "\n",
    "if not TEST_FOLDER:\n",
    "    all_files = os.listdir(TRAIN_FOLDER)\n",
    "    all_files.sort(key=sort_index)\n",
    "    test_index = len(all_files) // TEST_RATIO\n",
    "    test_files = all_files[-test_index:]\n",
    "    train_files = all_files[:-test_index]\n",
    "else:\n",
    "    train_files = os.listdir(TRAIN_FOLDER)\n",
    "    test_files = os.listdir(TEST_FOLDER)\n",
    "\n",
    "print(f\"Files for training: {len(train_files)}\")\n",
    "print(f\"Files for testing: {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files for training: 15228\n",
      "Files for validation: 3806\n",
      "Validation file samples: ['2181-dallas-buyers-club-eng-1.wav', '2181-mission-impossible-iv-1.wav', '2181-the-dark-knight-rises-eng-0.wav', '2181-the-kingdom-of-heaven-eng-1.wav', '2181-the-kings-speech-eng-0.wav']\n"
     ]
    }
   ],
   "source": [
    "# Train/Validation split\n",
    "\n",
    "if SHUFFLE:\n",
    "    random.shuffle(train_files)\n",
    "\n",
    "if not BUILD_TEST:\n",
    "    train_files.extend(test_files)\n",
    "\n",
    "valid_idx = len(train_files) // VALID_RATIO\n",
    "valid_files = train_files[-valid_idx:]\n",
    "train_files = train_files[:-valid_idx]\n",
    "\n",
    "print(f\"Files for training: {len(train_files)}\")\n",
    "print(f\"Files for validation: {len(valid_files)}\")\n",
    "print(f\"Validation file samples: {valid_files[:5]}\")"
   ]
  },
  {
   "source": [
    "## Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csrc.dataset import PANNsDataset"
   ]
  },
  {
   "source": [
    "## Transformer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csrc.transformers import BaseAug"
   ]
  },
  {
   "source": [
    "## Set up dataloader "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {\n",
    "    \"train\": data.DataLoader(PANNsDataset(train_files, training_folder=TRAIN_WORKING_FOLDER, test_folder=TEST_WORKING_FOLDER, waveform_transforms=BaseAug), # Build training set\n",
    "                            batch_size=BS,\n",
    "                            shuffle=True,\n",
    "                            num_workers=0,\n",
    "                            pin_memory=True,\n",
    "                            drop_last=True),\n",
    "    \"valid\": data.DataLoader(PANNsDataset(valid_files, training_folder=TRAIN_WORKING_FOLDER, test_folder=TEST_WORKING_FOLDER, waveform_transforms=None), # Build training set.\\n\",\n",
    "                             batch_size=BS,\n",
    "                             shuffle=False,\n",
    "                             num_workers=0,\n",
    "                             pin_memory=True,\n",
    "                             drop_last=False)\n",
    "}"
   ]
  },
  {
   "source": [
    "## Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csrc.models import AttBlock, PANNsCNN14Att"
   ]
  },
  {
   "source": [
    "## Loss"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csrc.losses import ImprovedPANNsLoss"
   ]
  },
  {
   "source": [
    "## Callbacks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csrc.callbacks import F1Callback, mAPCallback, PrecisionCallback"
   ]
  },
  {
   "source": [
    "## Training Configurations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "# model\n",
    "model = PANNsCNN14Att(**MC.sed_model_config)\n",
    "weights = torch.load(WEIGHTS_PATH)\n",
    "model.load_state_dict(weights[\"model\"])\n",
    "model.att_block = AttBlock(2048, 2, activation=\"sigmoid\")\n",
    "model.att_block.init_weights()\n",
    "model.to(device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# scheduler\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "# loss\n",
    "loss = ImprovedPANNsLoss().to(device)\n",
    "\n",
    "# callbacks\n",
    "callbacks = [\n",
    "    F1Callback(),\n",
    "    mAPCallback(),\n",
    "    PrecisionCallback(),\n",
    "    CheckpointCallback(save_n_best=0),\n",
    "]"
   ]
  },
  {
   "source": [
    "## Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/50 * Epoch (train):   0% 1/317 [00:08<46:01,  8.74s/it, loss=nan, mAP=0.500, macro_f1=0.262, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   1% 2/317 [00:10<25:16,  4.81s/it, loss=nan, mAP=0.500, macro_f1=0.226, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   1% 3/317 [00:12<18:02,  3.45s/it, loss=nan, mAP=0.500, macro_f1=0.294, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   1% 4/317 [00:14<14:26,  2.77s/it, loss=nan, mAP=0.500, macro_f1=0.304, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   2% 5/317 [00:17<14:45,  2.84s/it, loss=nan, mAP=0.500, macro_f1=0.213, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   2% 6/317 [00:19<13:19,  2.57s/it, loss=nan, mAP=0.500, macro_f1=0.294, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   2% 7/317 [00:21<13:19,  2.58s/it, loss=nan, mAP=0.500, macro_f1=0.294, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   3% 8/317 [00:24<12:45,  2.48s/it, loss=nan, mAP=0.500, macro_f1=0.342, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   3% 9/317 [00:26<11:47,  2.30s/it, loss=nan, mAP=0.500, macro_f1=0.273, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   3% 10/317 [00:27<10:26,  2.04s/it, loss=nan, mAP=0.500, macro_f1=0.226, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   3% 11/317 [00:30<11:09,  2.19s/it, loss=nan, mAP=0.500, macro_f1=0.284, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   4% 12/317 [00:32<11:23,  2.24s/it, loss=nan, mAP=0.500, macro_f1=0.294, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   4% 13/317 [00:33<09:45,  1.92s/it, loss=nan, mAP=0.500, macro_f1=0.273, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   4% 14/317 [00:35<10:08,  2.01s/it, loss=nan, mAP=0.500, macro_f1=0.284, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   5% 15/317 [00:37<08:57,  1.78s/it, loss=nan, mAP=0.500, macro_f1=0.213, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   5% 16/317 [00:38<08:42,  1.73s/it, loss=nan, mAP=0.500, macro_f1=0.226, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   5% 17/317 [00:40<09:20,  1.87s/it, loss=nan, mAP=0.500, macro_f1=0.284, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   6% 18/317 [00:43<09:59,  2.00s/it, loss=nan, mAP=0.500, macro_f1=0.273, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   6% 19/317 [00:45<09:38,  1.94s/it, loss=nan, mAP=0.500, macro_f1=0.262, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   6% 20/317 [00:47<09:42,  1.96s/it, loss=nan, mAP=0.500, macro_f1=0.250, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   7% 21/317 [00:49<09:51,  2.00s/it, loss=nan, mAP=0.500, macro_f1=0.238, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   7% 22/317 [00:51<10:21,  2.11s/it, loss=nan, mAP=0.500, macro_f1=0.238, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   7% 23/317 [00:53<10:21,  2.11s/it, loss=nan, mAP=0.500, macro_f1=0.172, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   8% 24/317 [00:55<10:06,  2.07s/it, loss=nan, mAP=0.500, macro_f1=0.284, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   8% 25/317 [00:57<09:57,  2.04s/it, loss=nan, mAP=0.500, macro_f1=0.294, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   8% 26/317 [01:00<10:46,  2.22s/it, loss=nan, mAP=0.500, macro_f1=0.250, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   9% 27/317 [01:02<10:51,  2.25s/it, loss=nan, mAP=0.500, macro_f1=0.324, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   9% 28/317 [01:05<11:14,  2.33s/it, loss=nan, mAP=0.500, macro_f1=0.314, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   9% 29/317 [01:07<11:29,  2.40s/it, loss=nan, mAP=0.500, macro_f1=0.284, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):   9% 30/317 [01:09<10:21,  2.17s/it, loss=nan, mAP=0.500, macro_f1=0.333, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  10% 31/317 [01:11<10:38,  2.23s/it, loss=nan, mAP=0.500, macro_f1=0.284, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  10% 32/317 [01:13<09:37,  2.03s/it, loss=nan, mAP=0.500, macro_f1=0.158, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  10% 33/317 [01:15<09:19,  1.97s/it, loss=nan, mAP=0.500, macro_f1=0.284, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  11% 34/317 [01:17<09:40,  2.05s/it, loss=nan, mAP=0.500, macro_f1=0.314, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  11% 35/317 [01:19<10:10,  2.16s/it, loss=nan, mAP=0.500, macro_f1=0.273, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  11% 36/317 [01:22<10:38,  2.27s/it, loss=nan, mAP=0.500, macro_f1=0.262, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  12% 37/317 [01:23<09:36,  2.06s/it, loss=nan, mAP=0.500, macro_f1=0.324, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  12% 38/317 [01:25<08:47,  1.89s/it, loss=nan, mAP=0.500, macro_f1=0.250, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  12% 39/317 [01:27<09:02,  1.95s/it, loss=nan, mAP=0.500, macro_f1=0.262, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  13% 40/317 [01:29<09:30,  2.06s/it, loss=nan, mAP=0.500, macro_f1=0.250, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  13% 41/317 [01:31<09:48,  2.13s/it, loss=nan, mAP=0.500, macro_f1=0.314, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  13% 42/317 [01:33<09:23,  2.05s/it, loss=nan, mAP=0.500, macro_f1=0.262, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  14% 43/317 [01:35<08:40,  1.90s/it, loss=nan, mAP=0.500, macro_f1=0.262, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  14% 44/317 [01:37<08:17,  1.82s/it, loss=nan, mAP=0.500, macro_f1=0.273, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  14% 45/317 [01:39<09:07,  2.01s/it, loss=nan, mAP=0.500, macro_f1=0.351, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  15% 46/317 [01:41<09:38,  2.14s/it, loss=nan, mAP=0.500, macro_f1=0.226, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  15% 47/317 [01:44<09:39,  2.15s/it, loss=nan, mAP=0.500, macro_f1=0.360, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  15% 48/317 [01:46<09:36,  2.14s/it, loss=nan, mAP=0.500, macro_f1=0.226, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  15% 49/317 [01:48<09:20,  2.09s/it, loss=nan, mAP=0.500, macro_f1=0.294, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  16% 50/317 [01:49<08:56,  2.01s/it, loss=nan, mAP=0.500, macro_f1=0.273, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  16% 51/317 [01:52<09:20,  2.11s/it, loss=nan, mAP=0.500, macro_f1=0.304, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  16% 52/317 [01:54<10:00,  2.27s/it, loss=nan, mAP=0.500, macro_f1=0.284, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  17% 53/317 [01:57<10:31,  2.39s/it, loss=nan, mAP=0.500, macro_f1=0.273, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  17% 54/317 [01:59<10:25,  2.38s/it, loss=nan, mAP=0.500, macro_f1=0.284, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  17% 55/317 [02:01<09:38,  2.21s/it, loss=nan, mAP=0.500, macro_f1=0.250, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  18% 56/317 [02:04<09:49,  2.26s/it, loss=nan, mAP=0.500, macro_f1=0.284, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  18% 57/317 [02:06<10:00,  2.31s/it, loss=nan, mAP=0.500, macro_f1=0.294, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  18% 58/317 [02:08<09:27,  2.19s/it, loss=nan, mAP=0.500, macro_f1=0.262, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  19% 59/317 [02:10<08:50,  2.06s/it, loss=nan, mAP=0.500, macro_f1=0.250, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  19% 60/317 [02:12<09:18,  2.17s/it, loss=nan, mAP=0.500, macro_f1=0.284, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  19% 61/317 [02:14<09:03,  2.12s/it, loss=nan, mAP=0.500, macro_f1=0.284, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  20% 62/317 [02:16<08:30,  2.00s/it, loss=nan, mAP=0.500, macro_f1=0.250, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  20% 63/317 [02:18<08:15,  1.95s/it, loss=nan, mAP=0.500, macro_f1=0.262, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  20% 64/317 [02:20<09:04,  2.15s/it, loss=nan, mAP=0.500, macro_f1=0.314, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  21% 65/317 [02:23<09:04,  2.16s/it, loss=nan, mAP=0.500, macro_f1=0.314, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  21% 66/317 [02:25<09:01,  2.16s/it, loss=nan, mAP=0.500, macro_f1=0.262, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  21% 67/317 [02:27<09:08,  2.19s/it, loss=nan, mAP=0.500, macro_f1=0.262, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "1/50 * Epoch (train):  21% 68/317 [02:29<08:54,  2.15s/it, loss=nan, mAP=0.500, macro_f1=0.273, precision=0.000e+00]WARNING:root:NaN or Inf found in input tensor.\n",
      "Early exiting\n",
      "1/50 * Epoch (train):  21% 68/317 [02:31<08:54,  2.15s/it, loss=nan, mAP=0.500, macro_f1=0.273, precision=0.000e+00]"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "runner = SupervisedRunner(\n",
    "    device=device,\n",
    "    input_key=\"waveform\",\n",
    "    input_target_key=\"targets\")\n",
    "\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=loss,\n",
    "    loaders=loaders,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=EPOCHS,\n",
    "    verbose=True,\n",
    "    logdir=LOG_DIR,\n",
    "    callbacks=callbacks,\n",
    "    main_metric=\"mAP\",\n",
    "    minimize_metric=False,\n",
    "    # fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}